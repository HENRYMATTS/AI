{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf19a55f-6c6b-4c6e-9c60-438c2d67fd3a",
   "metadata": {},
   "source": [
    "# Intro to Frozen Lake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4197d880-320c-43af-b9ec-a0b2b0f79972",
   "metadata": {},
   "source": [
    "A deep neural network (DQN) controlled AI agent learns to navigate the frozen lake environment.\n",
    "This environment was implemented using pygame a python graphics library. It was inspired by frozen lake environment in the OpenAi's gym library. A library that provides various environments for Reinforcenment Learning.\n",
    "The Agent (blue square) moves from the starting point (brown square) traverses the environment looking for the best path to reach the goal (red square) while avoiding falling into holes (black square)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a58e9f7-0cd0-4524-87f1-9bd66746ca1e",
   "metadata": {},
   "source": [
    "# Environment and Training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa99976f-f600-4032-8ea2-88253c9bdc64",
   "metadata": {},
   "source": [
    "Once the training loop is complete, the weights are stored in the Trained_models folder in this format model_1000.\n",
    "The name of the weights has a No. that indicates the number of Epochs or for how long the model trained.\n",
    "The greater the training cycles/Epochs the better the model performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9478d36f-604a-4cb7-9550-7536760fb729",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pygame,random,sys\n",
    "from pygame.locals import*\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "\n",
    "# Environment class\n",
    "class FrozenLake():\n",
    "    def __init__(self):\n",
    "        # Constants\n",
    "        self.GRID_SIZE = 4\n",
    "        self.SQUARE_SIZE = 100\n",
    "        self.WINDOW_SIZE = self.GRID_SIZE * self.SQUARE_SIZE\n",
    "        self.PLAYER_COLOR = (0, 0, 255)  # Green\n",
    "        #self.actions = [ 1 , 2  , 3 , 4] # up , down , left , right\n",
    "        \n",
    "        # Initialize Pygame\n",
    "        pygame.init()\n",
    "        self.screen = pygame.display.set_mode((self.WINDOW_SIZE, self.WINDOW_SIZE))\n",
    "        pygame.display.set_caption(\"Frozen Lake\")\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "        # Player position\n",
    "        self.player_x, self.player_y = 0,0\n",
    "    \n",
    "    def reset(self):\n",
    "        self.player_x = 0\n",
    "        self.player_y = 0\n",
    "        return [self.player_x , self. player_y]\n",
    "        \n",
    "    def draw(self,action,env_map):\n",
    "        \n",
    "        done = False\n",
    "        if action == 2 and self.player_x < self.GRID_SIZE - 1:\n",
    "            self.player_x += 1\n",
    "        elif action == 1 and self.player_x > 0:\n",
    "            self.player_x -= 1\n",
    "        elif action == 0 and self.player_y < self.GRID_SIZE - 1:\n",
    "            self.player_y += 1\n",
    "        # elif action == 0 and self.player_y > 0:\n",
    "        #     self.player_y -= 1\n",
    "     \n",
    "      \n",
    "        self.screen.fill((255, 255, 255))\n",
    "       \n",
    "            # Draw the grid\n",
    "        for x in range(len(env_map)):\n",
    "            for y in range(len(env_map)):\n",
    "                rect = pygame.Rect(y * self.SQUARE_SIZE, x * self.SQUARE_SIZE, self.SQUARE_SIZE, self.SQUARE_SIZE)\n",
    "                if env_map[x,y]== 2:\n",
    "                    pygame.draw.rect(self.screen, (79,55, 39), rect)\n",
    "                    if self.player_x == y and self.player_y == x:\n",
    "                        reward = 0\n",
    "                        next_state = [y,x]\n",
    "                        done = False\n",
    "                elif env_map[x,y]== 1:\n",
    "                    pygame.draw.rect(self.screen, ('black'), rect,1)\n",
    "                    if self.player_x == y and self.player_y == x:\n",
    "                        reward = 0\n",
    "                        next_state = [y,x]\n",
    "                        if env_map[2,1] or env_map[2,2] or env_map[3,1] or env_map[3,1]:\n",
    "                            reward = 40\n",
    "                            \n",
    "                elif env_map[x,y] == 3:    \n",
    "                    pygame.draw.rect(self.screen, ('red'), rect)\n",
    "                    if self.player_x == y and self.player_y == x:\n",
    "                        reward = 200\n",
    "                        next_state = [y,x]\n",
    "                        done = True\n",
    "                        \n",
    "                       \n",
    "                   \n",
    "              \n",
    "                else:\n",
    "                    pygame.draw.rect(self.screen, ('black'), rect)\n",
    "                    if self.player_x == y and self.player_y == x:\n",
    "                        reward =  -120\n",
    "                        next_state = [y,x]\n",
    "                        done = True                \n",
    "\n",
    "        \n",
    "        # Draw the player\n",
    "        player_rect = pygame.Rect(self.player_x * self.SQUARE_SIZE, self.player_y * self.SQUARE_SIZE,\n",
    "                                      self.SQUARE_SIZE, self.SQUARE_SIZE)\n",
    "        pygame.draw.rect(self.screen, self.PLAYER_COLOR, player_rect)\n",
    "        \n",
    "        pygame.display.flip()\n",
    "        self.clock.tick(120)\n",
    "        return action,reward,next_state, done\n",
    "\n",
    "\n",
    "# Neural Network\n",
    "class PolicyNet(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        super(PolicyNet,self).__init__()\n",
    "        self.l1 = nn.Linear(input_size,256)\n",
    "        self.l2 = nn.Linear(256, 256)\n",
    "        self.l3 = nn.Linear(256, output_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = self.l3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Experience Replay\n",
    "class Experience():\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, state, action, reward, next_state):\n",
    "        self.memory.append((state, action, reward, next_state))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "\n",
    "#hyperparameters\n",
    "input_size = 2  \n",
    "output_size = 3\n",
    "gamma = 0.9\n",
    "epsilon = 1\n",
    "epsilon_min = 0.1\n",
    "epsilon_decay = 0.995\n",
    "learning_rate = 0.001\n",
    "replay_capacity = 10000\n",
    "batch_size = 100\n",
    "\n",
    "#initialise all the classes\n",
    "#  PolicyNet and target DQNs\n",
    "policy = PolicyNet(input_size,output_size)\n",
    "target = PolicyNet(input_size,output_size)\n",
    "target.load_state_dict(policy.state_dict())  # Copy policy weights to target network\n",
    "# target.eval()  # Set target network to evaluation mode\n",
    "\n",
    "#  environment and experience replay memory\n",
    "env = FrozenLake()\n",
    "replay = Experience(replay_capacity)\n",
    "\n",
    "# loss $ optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(policy.parameters(), lr=learning_rate)\n",
    "\n",
    "# frozen lake environment map\n",
    "env_map = np.array([\n",
    "                    [2,1,1,1],\n",
    "                    [1,0,1,0],\n",
    "                    [1,1,1,0],\n",
    "                    [0,1,1,3]\n",
    "                  ])\n",
    "\n",
    "# Training loop\n",
    "for episodes in range(15000):\n",
    "    state = torch.tensor( env.reset(), dtype=torch.float)\n",
    "    state = state.view(1,-1)\n",
    "    done = False\n",
    "    for episode in range(200):\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == QUIT or event.type == KEYUP and event.key == K_ESCAPE:\n",
    "                pygame.quit()\n",
    "                sys.exit()\n",
    "      \n",
    "        if random.random() < epsilon:\n",
    "           \n",
    "            action = random.randint(0,2)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                q_values = policy(state)\n",
    "                action = torch.argmax(q_values).item()\n",
    "\n",
    "               \n",
    "\n",
    "        action,reward,next_state, done = env.draw(action,env_map)\n",
    "        next_state = torch.tensor( next_state, dtype=torch.float)\n",
    "        next_state = next_state.view(1,-1)\n",
    "        \n",
    "        replay.push(state,torch.tensor([action]),torch.tensor([reward]), next_state)\n",
    "        \n",
    "        if len(replay.memory) >= batch_size:\n",
    "            samples = random.choice(replay.memory)\n",
    "            \n",
    "            q_values = policy(samples[0]).squeeze(0)\n",
    "            q_value = q_values[samples[1]]\n",
    "            \n",
    "            \n",
    "            max_q_value = target(samples[3]).max(1)[0].detach()\n",
    "            target_q_value = samples[2] + gamma * max_q_value\n",
    "           \n",
    "            loss = criterion(q_value, target_q_value)\n",
    "           \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        \n",
    "        state = next_state\n",
    "        if done:\n",
    "            break\n",
    "    epsilon = max(epsilon * epsilon_decay, epsilon_min)      \n",
    "    if episodes % 10 == 0:\n",
    "        target.load_state_dict(policy.state_dict())\n",
    "        \n",
    "torch.save(policy.state_dict(), 'model_15000.pth')    \n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb30dca-93cb-49c0-b405-9c5ea4944545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045c3fec-99f2-47d4-b73d-3fc8ac130e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e35fb8a-3083-4790-89ac-723ea635aaf9",
   "metadata": {},
   "source": [
    "# Testing the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b8d4ec1-c0b5-4b2a-a0df-7da5fb93cd1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pygame,random,sys\n",
    "from pygame.locals import*\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "\n",
    "# Environment class\n",
    "class FrozenLake():\n",
    "    def __init__(self):\n",
    "        # Constants\n",
    "        self.GRID_SIZE = 4\n",
    "        self.SQUARE_SIZE = 100\n",
    "        self.WINDOW_SIZE = self.GRID_SIZE * self.SQUARE_SIZE\n",
    "        self.PLAYER_COLOR = (0, 0, 255)  # Green\n",
    "        #self.actions = [ 1 , 2  , 3 , 4] # up , down , left , right\n",
    "        \n",
    "        # Initialize Pygame\n",
    "        pygame.init()\n",
    "        self.screen = pygame.display.set_mode((self.WINDOW_SIZE, self.WINDOW_SIZE))\n",
    "        pygame.display.set_caption(\"Frozen Lake\")\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "        # Player position\n",
    "        self.player_x, self.player_y = 0,0\n",
    "    \n",
    "    def reset(self):\n",
    "        self.player_x = 0\n",
    "        self.player_y = 0\n",
    "        return [self.player_x , self. player_y]\n",
    "        \n",
    "    def draw(self,action,env_map):\n",
    "        \n",
    "        done = False\n",
    "        if action == 2 and self.player_x < self.GRID_SIZE - 1:\n",
    "            self.player_x += 1\n",
    "        elif action == 1 and self.player_x > 0:\n",
    "            self.player_x -= 1\n",
    "        elif action == 0 and self.player_y < self.GRID_SIZE - 1:\n",
    "            self.player_y += 1\n",
    "        # elif action == 0 and self.player_y > 0:\n",
    "        #     self.player_y -= 1\n",
    "     \n",
    "     \n",
    "      \n",
    "        self.screen.fill((255, 255, 255))\n",
    "       \n",
    "            # Draw the grid\n",
    "        for x in range(len(env_map)):\n",
    "            for y in range(len(env_map)):\n",
    "                rect = pygame.Rect(y * self.SQUARE_SIZE, x * self.SQUARE_SIZE, self.SQUARE_SIZE, self.SQUARE_SIZE)\n",
    "                if env_map[x,y]== 2:\n",
    "                    pygame.draw.rect(self.screen, (79,55, 39), rect)\n",
    "                    if self.player_x == y and self.player_y == x:\n",
    "                        reward = 0\n",
    "                        next_state = [y,x]\n",
    "                        done = False\n",
    "                elif env_map[x,y]== 1:\n",
    "                    pygame.draw.rect(self.screen, ('black'), rect,1)\n",
    "                    if self.player_x == y and self.player_y == x:\n",
    "                        reward = 0\n",
    "                        next_state = [y,x]\n",
    "                        if env_map[2,1] or env_map[2,2] or env_map[3,1] or env_map[3,1]:\n",
    "                            reward = 40\n",
    "                            \n",
    "                      \n",
    "                elif env_map[x,y] == 3:    \n",
    "                    pygame.draw.rect(self.screen, ('red'), rect)\n",
    "                    if self.player_x == y and self.player_y == x:\n",
    "                        reward = 200\n",
    "                        next_state = [y,x]\n",
    "                        done = True\n",
    "                   \n",
    "              \n",
    "                else:\n",
    "                    pygame.draw.rect(self.screen, ('black'), rect)\n",
    "                    if self.player_x == y and self.player_y == x:\n",
    "                        reward =  -120\n",
    "                        next_state = [y,x]\n",
    "                        done = True                \n",
    "\n",
    "        \n",
    "        # Draw the player\n",
    "        player_rect = pygame.Rect(self.player_x * self.SQUARE_SIZE, self.player_y * self.SQUARE_SIZE,\n",
    "                                      self.SQUARE_SIZE, self.SQUARE_SIZE)\n",
    "        pygame.draw.rect(self.screen, self.PLAYER_COLOR, player_rect)\n",
    "        \n",
    "        pygame.display.flip()\n",
    "        self.clock.tick(1)\n",
    "        return action,reward,next_state, done\n",
    "\n",
    "\n",
    "# Neural Network\n",
    "class PolicyNet(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        super(PolicyNet,self).__init__()\n",
    "        self.l1 = nn.Linear(input_size,256)\n",
    "        self.l2 = nn.Linear(256,256)\n",
    "        self.l3 = nn.Linear(256, output_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = self.l3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "#hyperparameters\n",
    "input_size = 2  \n",
    "output_size = 3 \n",
    "\n",
    "#initialise all the classes\n",
    "#  PolicyNet and target DQNs\n",
    "policy = PolicyNet(input_size,output_size)\n",
    "policy.load_state_dict(torch.load('model_10000.pth'))\n",
    "policy.eval()  # Set the model to evaluation mode\n",
    "\n",
    "env = FrozenLake()\n",
    "\n",
    "\n",
    "\n",
    "# frozen lake environment map\n",
    "env_map = np.array([\n",
    "                    [2,1,1,1],\n",
    "                    [1,0,1,0],\n",
    "                    [1,1,1,0],\n",
    "                    [0,1,1,3]\n",
    "                  ])\n",
    "\n",
    "state = torch.tensor( env.reset(), dtype=torch.float)\n",
    "state = state.view(1,-1)\n",
    "done = False\n",
    "while True:\n",
    "   \n",
    "    for event in pygame.event.get():\n",
    "        if event.type == QUIT or event.type == KEYUP and event.key == K_ESCAPE:\n",
    "            pygame.quit()\n",
    "            sys.exit()\n",
    "    \n",
    "       \n",
    "    with torch.no_grad():\n",
    "        q_values = policy(state)\n",
    "      \n",
    "    action = q_values.argmax().item()\n",
    "    action,reward,next_state, done = env.draw(action,env_map)\n",
    "    next_state = torch.tensor(next_state,dtype=torch.float) \n",
    "    if done == True:\n",
    "        state = torch.tensor( env.reset(), dtype=torch.float)\n",
    "        state = state.view(1,-1)\n",
    "        \n",
    "    state = next_state\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76110ee5-ad63-4989-8dbc-442ac5950e05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b3a66e-e1cb-4174-8afc-cf49c5332efe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b6a3f4b-97ef-404e-8460-c529be6a63a3",
   "metadata": {},
   "source": [
    "# Frozen Lake Human player\n",
    "This version is played by a human controller via the down , left and right arrow keys since the agent has only three directions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "143fd4b4-dd0f-49b8-8e8b-ee5a8d442299",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import sys\n",
    "from pygame.locals import *\n",
    "import numpy as np\n",
    "\n",
    "class FrozenLake():\n",
    "    def __init__(self):\n",
    "        # Constants\n",
    "        self.GRID_SIZE = 4\n",
    "        self.SQUARE_SIZE = 100\n",
    "        self.WINDOW_SIZE = self.GRID_SIZE * self.SQUARE_SIZE\n",
    "        self.PLAYER_COLOR = (0, 0, 255)  # Green\n",
    "\n",
    "        # Initialize Pygame\n",
    "        pygame.init()\n",
    "        self.screen = pygame.display.set_mode((self.WINDOW_SIZE, self.WINDOW_SIZE))\n",
    "        pygame.display.set_caption(\"Frozen Lake\")\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "        # Player position\n",
    "        self.player_x, self.player_y = 0, 0\n",
    "\n",
    "       \n",
    "    def reset(self):\n",
    "        self.player_x = 0\n",
    "        self.player_y = 0\n",
    "        return [self.player_x , self. player_y]\n",
    "    \n",
    "    def draw(self,env_map):\n",
    "     \n",
    "        while True:\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == QUIT or event.type == KEYUP and event.key == K_ESCAPE:\n",
    "                    pygame.quit()\n",
    "                    sys.exit()\n",
    "                elif event.type == KEYDOWN:\n",
    "                    if event.key == K_RIGHT and self.player_x < self.GRID_SIZE - 1:\n",
    "                        self.player_x += 1\n",
    "                    elif event.key == K_LEFT and self.player_x > 0:\n",
    "                        self.player_x -= 1\n",
    "                    elif event.key == K_DOWN and self.player_y < self.GRID_SIZE - 1:\n",
    "                        self.player_y += 1\n",
    "                    # elif event.key == K_UP and self.player_y > 0:\n",
    "                    #     self.player_y -= 1\n",
    "\n",
    "            self.screen.fill((255, 255, 255))\n",
    "\n",
    "            # Draw the grid\n",
    "            for x in range(len(env_map)):\n",
    "                for y in range(len(env_map)):\n",
    "                    rect = pygame.Rect(y * self.SQUARE_SIZE, x * self.SQUARE_SIZE, self.SQUARE_SIZE, self.SQUARE_SIZE)\n",
    "                    if env_map[x,y]== 2:\n",
    "                        pygame.draw.rect(self.screen, (79,55, 39), rect)\n",
    "                        if self.player_x == y and self.player_y == x:\n",
    "                            reward = 0\n",
    "                            next_state = [y,x]\n",
    "                            done = False\n",
    "                        \n",
    "                        \n",
    "                    elif env_map[x,y]== 1:\n",
    "                        pygame.draw.rect(self.screen, ('black'), rect,1)\n",
    "                        if self.player_x == y and self.player_y == x:\n",
    "                            reward = 0\n",
    "                            next_state = [y,x]\n",
    "                            if env_map[2,1] or env_map[2,2] or env_map[3,1] or env_map[3,1]:\n",
    "                                reward = 40\n",
    "                      \n",
    "                    elif env_map[x,y] == 3:    \n",
    "                        pygame.draw.rect(self.screen, ('red'), rect)\n",
    "                        if self.player_x == y and self.player_y == x:\n",
    "                            reward = 200\n",
    "                            next_state = [y,x]\n",
    "                            done = True\n",
    "\n",
    "                    else:\n",
    "                        pygame.draw.rect(self.screen, ('black'), rect)\n",
    "                        if self.player_x == y and self.player_y == x:\n",
    "                            reward =  -120\n",
    "                            next_state = [y,x]\n",
    "                            done = True\n",
    "                         \n",
    "            # Draw the player\n",
    "            player_rect = pygame.Rect(self.player_x * self.SQUARE_SIZE, self.player_y * self.SQUARE_SIZE,\n",
    "                                      self.SQUARE_SIZE, self.SQUARE_SIZE)\n",
    "            pygame.draw.rect(self.screen, self.PLAYER_COLOR, player_rect)\n",
    "            if done:\n",
    "                self.reset()\n",
    "            pygame.display.update()\n",
    "            self.clock.tick(30)\n",
    "\n",
    "       \n",
    "# Create an instance of the GridGame class to run the game\n",
    "env = FrozenLake()\n",
    "env_map = np.array([\n",
    "                    [2,1,1,1],\n",
    "                    [1,0,1,0],\n",
    "                    [1,1,1,0],\n",
    "                    [0,1,1,3]\n",
    "                  ])\n",
    "env.draw(env_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8e0961-c41d-4514-b821-dec0ce64c021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
